name: Deploy Karpenter and HPA

on:
  push:
    branches: [ main ]
  workflow_dispatch:

env:
  AWS_REGION: us-west-2
  CLUSTER_NAME: wiary
  KARPENTER_VERSION: 0.16.3
  KUBECONFIG: /home/runner/.kube/config
  KARPENTER_ROLE_NAME: KarpenterNodeInstanceRole
  AWS_ACCOUNT_ID: 688567288847

jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3

    - name: Validate required secrets
      run: |
        if [ -z "${{ secrets.AWS_ACCESS_KEY_ID }}" ]; then
          echo "Error: AWS_ACCESS_KEY_ID secret is not set"
          exit 1
        fi
        if [ -z "${{ secrets.AWS_SECRET_ACCESS_KEY }}" ]; then
          echo "Error: AWS_SECRET_ACCESS_KEY secret is not set"
          exit 1
        fi

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v1
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Create IAM Role
      run: |
        # Check if role exists
        if aws iam get-role --role-name ${{ env.KARPENTER_ROLE_NAME }} 2>/dev/null; then
          echo "Role ${{ env.KARPENTER_ROLE_NAME }} already exists"
        else
          # Create the IAM role with trust policy
          aws iam create-role \
            --role-name ${{ env.KARPENTER_ROLE_NAME }} \
            --assume-role-policy-document file://karpenter/karpenter-trust-policy.json

          # Attach required policies
          aws iam attach-role-policy \
            --role-name ${{ env.KARPENTER_ROLE_NAME }} \
            --policy-arn arn:aws:iam::aws:policy/AmazonEKSWorkerNodePolicy

          aws iam attach-role-policy \
            --role-name ${{ env.KARPENTER_ROLE_NAME }} \
            --policy-arn arn:aws:iam::aws:policy/AmazonEKS_CNI_Policy

          aws iam attach-role-policy \
            --role-name ${{ env.KARPENTER_ROLE_NAME }} \
            --policy-arn arn:aws:iam::aws:policy/AmazonEC2ContainerRegistryReadOnly
        fi

    - name: Install kubectl
      run: |
        curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
        chmod +x kubectl
        sudo mv kubectl /usr/local/bin/

    - name: Setup kubeconfig
      run: |
        mkdir -p /home/runner/.kube
        CLUSTER_ENDPOINT=$(aws eks describe-cluster --name ${{ env.CLUSTER_NAME }} --query "cluster.endpoint" --output text)
        CERTIFICATE_DATA=$(aws eks describe-cluster --name ${{ env.CLUSTER_NAME }} --query "cluster.certificateAuthority.data" --output text)
        echo "Cluster endpoint: $CLUSTER_ENDPOINT"
        echo "Certificate data: $CERTIFICATE_DATA"
        cat > ${{ env.KUBECONFIG }} << EOF
        apiVersion: v1
        kind: Config
        clusters:
        - cluster:
            server: ${CLUSTER_ENDPOINT}
            certificate-authority-data: ${CERTIFICATE_DATA}
          name: ${CLUSTER_NAME}
        contexts:
        - context:
            cluster: ${CLUSTER_NAME}
            user: aws
          name: aws
        current-context: aws
        preferences: {}
        users:
        - name: aws
          user:
            exec:
              apiVersion: client.authentication.k8s.io/v1beta1
              command: aws
              args:
                - eks
                - get-token
                - --cluster-name
                - ${CLUSTER_NAME}
              env:
                - name: AWS_ACCESS_KEY_ID
                  value: ${{ secrets.AWS_ACCESS_KEY_ID }}
                - name: AWS_SECRET_ACCESS_KEY
                  value: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
                - name: AWS_DEFAULT_REGION
                  value: ${{ env.AWS_REGION }}
              interactiveMode: Never
        EOF
        chmod 600 ${{ env.KUBECONFIG }}

    - name: Verify cluster access
      run: |
        aws sts get-caller-identity
        TOKEN=$(aws eks get-token --cluster-name ${{ env.CLUSTER_NAME }} --query 'status.token' --output text)
        echo "Token: $TOKEN"
        kubectl --token=$TOKEN get nodes

    - name: Create namespace
      run: |
        TOKEN=$(aws eks get-token --cluster-name ${{ env.CLUSTER_NAME }} --query 'status.token' --output text)
        kubectl --token=$TOKEN create namespace karpenter --dry-run=client -o yaml | kubectl --token=$TOKEN apply -f -

    - name: Create ServiceAccount
      run: |
        TOKEN=$(aws eks get-token --cluster-name ${{ env.CLUSTER_NAME }} --query 'status.token' --output text)
        # Update the role ARN in the ServiceAccount manifest
        sed -i "s|688567288847|${{ env.AWS_ACCOUNT_ID }}|g" karpenter/sa.yaml
        kubectl --token=$TOKEN apply -f karpenter/sa.yaml

    - name: Create Karpenter Secret
      run: |
        TOKEN=$(aws eks get-token --cluster-name ${{ env.CLUSTER_NAME }} --query 'status.token' --output text)
        # Create secret with required values
        cat << EOF | kubectl --token=$TOKEN apply -f -
        apiVersion: v1
        kind: Secret
        metadata:
          name: karpenter-config
          namespace: karpenter
        type: Opaque
        stringData:
          cluster-name: ${{ env.CLUSTER_NAME }}
          cluster-endpoint: $(aws eks describe-cluster --name ${{ env.CLUSTER_NAME }} --query "cluster.endpoint" --output text)
          aws-region: ${{ env.AWS_REGION }}
          aws-default-region: ${{ env.AWS_REGION }}
          instance-profile: ${{ env.KARPENTER_ROLE_NAME }}
          service-linked-role: "true"
          node-role: ${{ env.KARPENTER_ROLE_NAME }}
        EOF

    - name: Prepare Helm values
      run: |
        # Get values from secret
        TOKEN=$(aws eks get-token --cluster-name ${{ env.CLUSTER_NAME }} --query 'status.token' --output text)
        CLUSTER_NAME=$(kubectl --token=$TOKEN get secret karpenter-config -n karpenter -o jsonpath='{.data.cluster-name}' | base64 -d)
        CLUSTER_ENDPOINT=$(kubectl --token=$TOKEN get secret karpenter-config -n karpenter -o jsonpath='{.data.cluster-endpoint}' | base64 -d)
        AWS_REGION=$(kubectl --token=$TOKEN get secret karpenter-config -n karpenter -o jsonpath='{.data.aws-region}' | base64 -d)
        AWS_DEFAULT_REGION=$(kubectl --token=$TOKEN get secret karpenter-config -n karpenter -o jsonpath='{.data.aws-default-region}' | base64 -d)
        INSTANCE_PROFILE=$(kubectl --token=$TOKEN get secret karpenter-config -n karpenter -o jsonpath='{.data.instance-profile}' | base64 -d)
        SERVICE_LINKED_ROLE=$(kubectl --token=$TOKEN get secret karpenter-config -n karpenter -o jsonpath='{.data.service-linked-role}' | base64 -d)
        NODE_ROLE=$(kubectl --token=$TOKEN get secret karpenter-config -n karpenter -o jsonpath='{.data.node-role}' | base64 -d)

        # Replace variables in values.yaml
        sed -i "s|\${KARPENTER_CLUSTER_NAME}|$CLUSTER_NAME|g" karpenter/values.yaml
        sed -i "s|\${KARPENTER_CLUSTER_ENDPOINT}|$CLUSTER_ENDPOINT|g" karpenter/values.yaml
        sed -i "s|\${KARPENTER_AWS_REGION}|$AWS_REGION|g" karpenter/values.yaml
        sed -i "s|\${KARPENTER_AWS_DEFAULT_REGION}|$AWS_DEFAULT_REGION|g" karpenter/values.yaml
        sed -i "s|\${KARPENTER_INSTANCE_PROFILE}|$INSTANCE_PROFILE|g" karpenter/values.yaml
        sed -i "s|\${KARPENTER_SERVICE_LINKED_ROLE}|$SERVICE_LINKED_ROLE|g" karpenter/values.yaml
        sed -i "s|\${KARPENTER_NODE_ROLE}|$NODE_ROLE|g" karpenter/values.yaml

    - name: Install Karpenter
      run: |
        TOKEN=$(aws eks get-token --cluster-name ${{ env.CLUSTER_NAME }} --query 'status.token' --output text)
        helm repo add karpenter https://charts.karpenter.sh
        helm repo update
        helm install karpenter karpenter/karpenter \
          --namespace karpenter \
          --create-namespace \
          --version ${{ env.KARPENTER_VERSION }} \
          -f karpenter/values.yaml \
          --kube-token=$TOKEN

    - name: Apply Provisioner
      run: |
        TOKEN=$(aws eks get-token --cluster-name ${{ env.CLUSTER_NAME }} --query 'status.token' --output text)
        kubectl --token=$TOKEN apply -f karpenter/karpenter-provisioner.yaml
