name: Deploy Karpenter and HPA

on:
  push:
    branches: [ main ]
  workflow_dispatch:

env:
  AWS_REGION: us-west-2
  CLUSTER_NAME: wiary
  KARPENTER_VERSION: 0.16.3
  KUBECONFIG: ~/.kube/config

jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3

    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v1
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ env.AWS_REGION }}

    - name: Install kubectl
      run: |
        curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
        chmod +x kubectl
        sudo mv kubectl /usr/local/bin/

    - name: Install AWS CLI
      run: |
        curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
        unzip awscliv2.zip
        sudo ./aws/install --update

    - name: Configure AWS CLI
      run: |
        aws configure set aws_access_key_id ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws configure set aws_secret_access_key ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws configure set region ${{ env.AWS_REGION }}

    - name: Setup kubeconfig
      env:
        AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        AWS_DEFAULT_REGION: ${{ env.AWS_REGION }}
        KUBECONFIG: ${{ env.KUBECONFIG }}
      run: |
        CLUSTER_ENDPOINT=$(aws eks describe-cluster --name ${{ env.CLUSTER_NAME }} --query "cluster.endpoint" --output text)
        CERTIFICATE_DATA=$(aws eks describe-cluster --name ${{ env.CLUSTER_NAME }} --query "cluster.certificateAuthority.data" --output text)
        mkdir -p ~/.kube
        cat > ${{ env.KUBECONFIG }} << EOF
        apiVersion: v1
        kind: Config
        clusters:
        - cluster:
            server: $CLUSTER_ENDPOINT
            certificate-authority-data: $CERTIFICATE_DATA
          name: ${{ env.CLUSTER_NAME }}
        contexts:
        - context:
            cluster: ${{ env.CLUSTER_NAME }}
            user: aws
          name: aws
        current-context: aws
        preferences: {}
        users:
        - name: aws
          user:
            exec:
              apiVersion: client.authentication.k8s.io/v1beta1
              command: aws
              args:
                - eks
                - get-token
                - --cluster-name
                - ${{ env.CLUSTER_NAME }}
              env:
                - name: AWS_ACCESS_KEY_ID
                  value: ${{ secrets.AWS_ACCESS_KEY_ID }}
                - name: AWS_SECRET_ACCESS_KEY
                  value: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
                - name: AWS_DEFAULT_REGION
                  value: ${{ env.AWS_REGION }}
        EOF
        chmod 600 ${{ env.KUBECONFIG }}

    - name: Verify cluster access
      env:
        AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        AWS_DEFAULT_REGION: ${{ env.AWS_REGION }}
        KUBECONFIG: ${{ env.KUBECONFIG }}
      run: |
        kubectl --kubeconfig=${{ env.KUBECONFIG }} config view
        kubectl --kubeconfig=${{ env.KUBECONFIG }} get nodes

    - name: Install Karpenter
      env:
        AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        AWS_DEFAULT_REGION: ${{ env.AWS_REGION }}
        KUBECONFIG: ${{ env.KUBECONFIG }}
      run: |
        helm repo add karpenter https://charts.karpenter.sh
        helm repo update
        helm install karpenter karpenter/karpenter \
          --namespace karpenter \
          --create-namespace \
          --version ${{ env.KARPENTER_VERSION }} \
          --set controller.clusterName=${{ env.CLUSTER_NAME }} \
          --set controller.clusterEndpoint=$(aws eks describe-cluster --name ${{ env.CLUSTER_NAME }} --query "cluster.endpoint" --output text) \
          --set controller.aws.defaultInstanceProfile=KarpenterNodeInstanceProfile \
          --set controller.aws.useServiceLinkedRole=true \
          --set controller.podAnnotations."iam\.amazonaws\.com/role=KarpenterNodeInstanceRole" \
          --set controller.env[0].name=AWS_REGION \
          --set controller.env[0].value=${{ env.AWS_REGION }} \
          --set controller.env[1].name=AWS_DEFAULT_REGION \
          --set controller.env[1].value=${{ env.AWS_REGION }} \
          --set controller.env[2].name=CLUSTER_NAME \
          --set controller.env[2].value=${{ env.CLUSTER_NAME }} \
          --set controller.env[3].name=CLUSTER_ENDPOINT \
          --set controller.env[3].value=$(aws eks describe-cluster --name ${{ env.CLUSTER_NAME }} --query "cluster.endpoint" --output text)

    - name: Apply Provisioner
      env:
        AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        AWS_DEFAULT_REGION: ${{ env.AWS_REGION }}
        KUBECONFIG: ${{ env.KUBECONFIG }}
      run: |
        kubectl --kubeconfig=${{ env.KUBECONFIG }} apply -f provisioner/default-provisioner.yaml -n karpenter

    - name: Apply HPA
      env:
        AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
        AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        AWS_DEFAULT_REGION: ${{ env.AWS_REGION }}
        KUBECONFIG: ${{ env.KUBECONFIG }}
      run: |
        kubectl --kubeconfig=${{ env.KUBECONFIG }} apply -f hpa/ -n karpenter

    - name: Update ASG
      run: |
        aws autoscaling update-auto-scaling-group \
          --auto-scaling-group-name ${{ secrets.ASG_NAME }} \
          --min-size 1 \
          --max-size 1 \
          --desired-capacity 1